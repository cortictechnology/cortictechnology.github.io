<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Creating a New Service</title>
    <link rel="stylesheet" href="cortic_styles.css">
    <link rel="stylesheet" href="dracula.css" />
    <script src="https://unpkg.com/@highlightjs/cdn-assets@11.7.0/highlight.min.js"></script>
    <!-- and it's easy to individually load additional languages -->
    <script src="https://unpkg.com/@highlightjs/cdn-assets@11.7.0/languages/javascript.min.js"></script>
    </script>
</head>

<body>
    <script>hljs.highlightAll();</script>
    <h1>Creating Your Service</h1>
    <p>This guide aims to instruct developers on creating a new service by subclassing from the base "Service" class
        available in the Cortic Platform SDK.</p>

    <h2>1. Create a New Service</h2>
    <ol>
        <li>Click the "Add Service" button in the Service panel of an App of your choice.</li>
        <div class="screenshot"><img src="./assets/create_service/add_service_button.png"></div>
        <li>Follow the prompts to name and configure your service's initial settings. Note that the
            Programming Handle is the name of the service invoking function that you can use in your code.</li>
        <div class="screenshot"><img src="./assets/create_service/create_service_dialog.png"></div>
        <li>Click "Add" to create the service.</li>
        <li>If you have finished setting up the VSCode path, you can press the "Edit Service" button to
            open the service's source code in VSCode.</li>
        <div class="screenshot"><img src="./assets/create_service/created_service.png"></div>

    </ol>

    <h2>2. Service Class Overview</h2>
    <p>For effective integration into the Cortic Platform, it is crucial for your service to implement three core
        methods:</p>
    <ul>
        <li><code>activate</code>
            <ul>
                <li>This method is called when the service is activated. It is responsible for initializing the service
                    and loading any required resources.</li>
            </ul>
        </li>
        <li><code>process</code>
            <ul>
                <li>This method is called when the service is invoked. It is responsible for processing the input and
                    returning the output.</li>
            </ul>
        </li>
        <li><code>deactivate</code>
            <ul>
                <li>This method is called when the service is deactivated. It is responsible for cleaning up any
                    resources and shutting down the service.</li>
            </ul>
        </li>
    </ul>

    <div class="screenshot"><img src="./assets/create_service/service_structure.png"></div>

    <h2>3. Platform Independent Services</h2>
    <p>Developing a service that remains independent of the underlying platform provides flexibility and broadens
        compatibility. There are three primary methods to achieve this:</p>

    <h3>1. Using Main Processor for Computations</h3>
    <p>By focusing on the main processor for all computations, you eschew the need for specialized hardware. This
        ensures a generic compatibility across platforms. The downside is that the performance may be suboptimal.</p>

    <h3>2. Leveraging Python Packages</h3>
    <p>Python packages such as PyTorch can support multiple backends. By utilizing such a package, you can abstract away
        the specifics of the backend and ensure your service works seamlessly across various platforms.</p>

    <h3>3. Conditional Requirements in <code>environment.yml</code></h3>
    <p>Edit the pip requirements section of <code>environment.yml</code> to add conditional requirements specific to
        each platform. This allows
        you to specify the requirements for each platform and ensure that only the relevant requirements are installed.
        In addition to this, you also need to detect the current platform within your
        service's running code to execute the relevant tasks.</p>
    <h3>4. Platform Dependent Packages</h3>
    <p>If your service requires packages that are only available on a specific platform, but cannot be installed
        using the methods mentioned above, you can use the post_conda_env_creation.py script to install the
        packages. This script is executed after the conda environment is created, and can be used to perform
        additional tasks such as installing packages that are not available on PyPI or conda-forge. Or you can
        use it to install packages that require additional steps to install, such as installing a package from a
        local file. When you create a new service, the post_conda_env_creation.py script is automatically
        created for you. You should perform the detection of the current platform within this script before
        installing the relevant packages.</p>

    <h2>4. Sample Service: Face Detection</h2>
    <p>To better understand the creation of a generic service, let's examine a face detection service for each of
        the
        scenarios mentioned above:</p>

    <h3>1. Main Processor-Based Face Detection</h3>
    <p>To illustrate the use of the main processor for computations, we will use Google's MediaPipe Face Detection
        package. This package is compatible with both the CPU and GPU, and we will use the CPU version for this
        example.</p>
    <p>First, we will need to add the following lines to the pip requirements section of the
        <code>environment.yml</code>
        file:
    </p>
    <pre><code class="language-python">mediapipe
</code></pre>

    <p> The <code>environment.yml</code> file should now look like this:</p>
    <pre><code class="language-python">
        name: cortic-face-detection
        channels:
            - defaults
            - anaconda
            - conda-forge
        dependencies:
            - python=3.9
            - pip
            - pip:
                - numpy
                - opencv-python
                - mediapipe
    </code></pre>

    <p>Next, we can then use the <code>mediapipe</code> package in our service's code:</p>
    <pre><code class="language-python">
        # service_main.py

        import os
        import mediapipe as mp
        from mediapipe.tasks import python
        from mediapipe.tasks.python import vision
        from cortic_platform.sdk.service import Service
        from cortic_platform.sdk.service_data_types import ServiceDataTypes

        class FaceDetection(Service):

            def __init__(self):
                super().__init__()

                self.input_type = {"camera_input": {"frame": ServiceDataTypes.CvFrame}}
                self.output_type = {"detected_faces": ServiceDataTypes.List}
                
                # You can download the model file in here: 
                # https://developers.google.com/mediapipe/solutions/vision/face_detector/index#models
                model_path = os.path.dirname(os.path.realpath(__file__)) + "/assets/face_detector.tflite"
                base_options = python.BaseOptions(model_asset_path=model_path)
                self.options = vision.FaceDetectorOptions(base_options=base_options)
                self.detector = None
                
            def activate(self):
                self.detector = vision.FaceDetector.create_from_options(self.options)

            def process(self, input_data=None):
                numpy_image = input_data["camera_input"]["frame"]
                image = mp.Image(image_format=mp.ImageFormat.SRGB, data=numpy_image)
                detection_result = self.detector.detect(image)
                detected_faces = self._process_result(numpy_image, detection_result)
                return {"detected_faces": detected_faces}

            def _process_result(self, image, detection_result):
                height, width, _ = image.shape
                detected_faces = []

                for detection in detection_result.detections:
                    bbox = detection.bounding_box
                    x1 = float(bbox.origin_x/width)
                    y1 = float(bbox.origin_y/height)
                    x2 = float((bbox.origin_x + bbox.width)/width)
                    y2 = float((bbox.origin_y + bbox.height)/height)
                    detected_faces.append([x1, y1, x2, y2])

                return detected_faces

            def deactivate(self):
                self.detector = None
        </code></pre>

    <p> Complete code for this service can be found <a
            href="https://github.com/cortictechnology/cortic-platform-samples/tree/main/services/face_detection"
            target="_blank">here</a>.</p>

    <h3>2. PyTorch Backend-Based Face Detection</h3>
    <p>To illustrate the use of a Python package that supports multiple backends, we will create a service based on
        the
        BlazeFace project by <a href="https://github.com/hollance/BlazeFace-PyTorch" target="_blank">hollance</a>.
        This
        project uses PyTorch as the underlying framework and supports multiple backends, including CPU, GPU, and
        Apple's
        MPS.
    </p>
    <p>First, we will need to add the following lines to the pip requirements section of the
        <code>environment.yml</code>file:
    </p>
    <pre><code class="language-python">
        torch
        torchvision
    </code></pre>

    <p> The <code>environment.yml</code> file should now look like this:</p>
    <pre><code class="language-python">
        name: cortic-face-detection
        channels:
            - defaults
            - anaconda
            - conda-forge
        dependencies:
            - python=3.9
            - pip
            - pip:
                - numpy
                - opencv-python
                - torch
    </code></pre>

    <p>Next, we can then use implement the service's code:</p>

    <pre><code class="language-python">
        # service_main.py
        # File used: 
        # https://github.com/hollance/BlazeFace-PyTorch/blob/master/blazeface.py
        # https://github.com/hollance/BlazeFace-PyTorch/blob/master/anchors.npy

        import os
        import torch
        import cv2
        from blazeface import BlazeFace # This is the file from the BlazeFace project by hollance
        from cortic_platform.sdk.service import Service
        from cortic_platform.sdk.service_data_types import ServiceDataTypes

        class FaceDetection(Service):

            def __init__(self):
                super().__init__()

                self.input_type = {"camera_input": {"frame": ServiceDataTypes.CvFrame}}
                self.output_type = {"detected_faces": ServiceDataTypes.List}
                
                # This is where the service decides which backend to use
                device = "cpu"
                if torch.cuda.is_available():
                    device = "cuda:0"
                elif torch.backends.mps.is_available():
                    device = "mps"
                self.device = torch.device(device)

                self.detector = None

            def activate(self):
                self.detector = BlazeFace().to(self.device)
                self.detector.load_weights(os.path.dirname(os.path.realpath(__file__)) + "/assets/blazeface.pth")
                self.detector.load_anchors(os.path.dirname(os.path.realpath(__file__)) + "/assets/anchors.npy")
                self.detector.min_score_thresh = 0.75

            def process(self, input_data=None):
                numpy_image = input_data["camera_input"]["frame"]
                img = cv2.cvtColor(numpy_image, cv2.COLOR_BGR2RGB)
                img = cv2.resize(img, (128, 128))
                detection_result = self.detector.predict_on_image(img)
                detected_faces = self._process_result(detection_result)
                return {"detected_faces": detected_faces}

            def _process_result(self, detection_result):
                detected_faces = []

                for i in range(detection_result.shape[0]):
                    y1 = detection_result[i, 0].item()
                    x1 = detection_result[i, 1].item()
                    y2 = detection_result[i, 2].item()
                    x2 = detection_result[i, 3].item()
                    detected_faces.append([x1, y1, x2, y2])

                return detected_faces

            def deactivate(self):
                self.detector = None
    </code></pre>

    <p> Complete code for this service can be found <a
            href="https://github.com/cortictechnology/cortic-platform-samples/tree/main/services/face_detction_pytorch"
            target="_blank">here</a>.</p>

    <h3>3. Conditional Requirements-Based Face Detection</h3>
    <p>To illustrate the use of conditional requirements, we will create a service that uses Google's MediaPipe Face
        Detection package for Linux and Windows, but uses a CoreML Blazeface model for macOS. This means that the
        we will need to add the following lines to the pip requirements section of the <code>environment.yml</code>
        file:</p>
    <pre><code class="language-python">
            mediapipe; sys_platform == "linux" or sys_platform == "win32"
            coremltools; sys_platform == "darwin"
        </code></pre>
    <p> The <code>environment.yml</code> file should now look like this:</p>
    <pre><code class="language-python">
            name: cortic-face-detection
            channels:
                - defaults
                - anaconda
                - conda-forge
            dependencies:
                - python=3.9
                - pip
                - pip:
                    - numpy
                    - opencv-python
                    - mediapipe; sys_platform == "linux" or sys_platform == "win32"
                    - coremltools; sys_platform == "darwin"
    </code></pre>
    <p>Then, we will need to detect the current platform within the service's running code to execute the relevant
        tasks. This can be done using the <code>platform</code> module:</p>
    <pre><code class="language-python">
        import platform

        if platform.system() == "Darwin":
            # macOS
            # Use CoreML Blazeface model
        else:
            # Linux or Windows
            # Use MediaPipe Face Detection package
    </code></pre>

    <p> The entire code for the face detection service is shown below:</p>

    <pre><code class="language-python">
        # service_main.py
        
        import os
        import platform
        from cortic_platform.sdk.service import Service
        from cortic_platform.sdk.service_data_types import ServiceDataTypes

        if platform.system() == "Darwin":
            from face_detector import FaceDetector
        else:
            import mediapipe as mp
            from mediapipe.tasks import python
            from mediapipe.tasks.python import vision

        class FaceDetectorMultiplaform(Service):
            def __init__(self):
                super().__init__()
                self.input_type = {"camera_input": {"frame": ServiceDataTypes.CvFrame}}
                self.output_type = {"detected_faces": ServiceDataTypes.List}
        
                if platform.system() != "Darwin":
                    # Linux or Windows
                    model_path = os.path.dirname(os.path.realpath(__file__)) + "/assets/face_detector.tflite"
                    base_options = python.BaseOptions(model_asset_path=model_path)
                    self.options = vision.FaceDetectorOptions(base_options=base_options)
        
                self.detector = None
        
            def activate(self):
                if platform.system() == "Darwin":
                    self.detector = FaceDetector()
                else:
                    self.detector = vision.FaceDetector.create_from_options(self.options)
        
            def process(self, input_data=None):
                frame = input_data["camera_input"]["frame"]
                if platform.system() == "Darwin":
                    detection_result = self.detector.run_inference(frame)
                else:
                    image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)
                    detection_result = self.detector.detect(image)
        
                detected_faces = self._process_result(frame, detection_result)
                return {"detected_faces": detected_faces}
            
            def _process_result(self, frame, detection_result):
                height, width, _ = frame.shape
                detected_faces = []
        
                if platform.system() == "Darwin":
                    for face in detection_result:
                        face_coordinates = face["face_coordinates"]
                        x1 = face_coordinates[0]
                        y1 = face_coordinates[1]
                        x2 = face_coordinates[2]
                        y2 = face_coordinates[3]
                        detected_faces.append([x1, y1, x2, y2])
                else:
                    for detection in detection_result.detections:
                        bbox = detection.bounding_box
                        x1 = float(bbox.origin_x/width)
                        y1 = float(bbox.origin_y/height)
                        x2 = float((bbox.origin_x + bbox.width)/width)
                        y2 = float((bbox.origin_y + bbox.height)/height)
                        detected_faces.append([x1, y1, x2, y2])
                return detected_faces
        
            def deactivate(self):
                self.detector = None
    </code></pre>

    <p> Complete code for this service can be found <a
            href="https://github.com/cortictechnology/cortic-platform-samples/tree/main/services/face_detector_multiplatform"
            target="_blank">here</a>.</p>
    <h2>Next Steps</h2>
    <p>Now that you have successfully created a service:</p>
    <ul>
        <li>Consider optimizing the service for better performance.</li>
        <li>Explore the Cortic Platform SDK to create more advanced services.</li>
        <li>Explore integrating additional functionalities to enhance the service capabilities.</li>
        <li>Look into the advanced features of the Cortic Platform SDK for more sophisticated implementations.</li>
    </ul>

</body>

</html>